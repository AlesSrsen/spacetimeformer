{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkkINLMGnnZX",
        "outputId": "e8393480-971d-4632-9e5b-99f5ef7f0e47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_83sKyHnTju",
        "outputId": "2cc9eaa0-e2ae-479a-9813-76ef02729d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Waiting for header\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,619 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,224 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,738 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,454 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,514 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,513 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.8 kB]\n",
            "Fetched 19.5 MB in 3s (7,465 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib mailcap mime-support\n",
            "  python3.8-minimal\n",
            "Suggested packages:\n",
            "  python3.8-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib mailcap mime-support python3.8\n",
            "  python3.8-minimal\n",
            "0 upgraded, 6 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 5,103 kB of archives.\n",
            "After this operation, 18.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-minimal amd64 3.8.20-1+jammy1 [796 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-minimal amd64 3.8.20-1+jammy1 [2,023 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-stdlib amd64 3.8.20-1+jammy1 [1,817 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8 amd64 3.8.20-1+jammy1 [440 kB]\n",
            "Fetched 5,103 kB in 12s (441 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 123630 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../1-python3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package mailcap.\n",
            "Preparing to unpack .../2-mailcap_3.70+nmu1ubuntu1_all.deb ...\n",
            "Unpacking mailcap (3.70+nmu1ubuntu1) ...\n",
            "Selecting previously unselected package mime-support.\n",
            "Preparing to unpack .../3-mime-support_3.66_all.deb ...\n",
            "Unpacking mime-support (3.66) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../4-libpython3.8-stdlib_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../5-python3.8_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Setting up mailcap (3.70+nmu1ubuntu1) ...\n",
            "Setting up mime-support (3.66) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8 (3.8.20-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "update-alternatives: using /usr/bin/python3.10 to provide /usr/bin/python3 (python3) in auto mode\n",
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in auto mode\n",
            "Python 3.8.20\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3.8-lib2to3\n",
            "The following NEW packages will be installed:\n",
            "  python3.8-distutils python3.8-lib2to3\n",
            "0 upgraded, 2 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 319 kB of archives.\n",
            "After this operation, 1,237 kB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-lib2to3 all 3.8.20-1+jammy1 [126 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-distutils all 3.8.20-1+jammy1 [193 kB]\n",
            "Fetched 319 kB in 2s (188 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3.8-lib2to3.\n",
            "(Reading database ... 124281 files and directories currently installed.)\n",
            "Preparing to unpack .../python3.8-lib2to3_3.8.20-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-lib2to3 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-distutils.\n",
            "Preparing to unpack .../python3.8-distutils_3.8.20-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-distutils (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-lib2to3 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-distutils (3.8.20-1+jammy1) ...\n",
            "--2024-12-02 14:43:28--  https://bootstrap.pypa.io/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2275758 (2.2M) [text/x-python]\n",
            "Saving to: ‘get-pip.py’\n",
            "\n",
            "get-pip.py          100%[===================>]   2.17M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-12-02 14:43:28 (45.7 MB/s) - ‘get-pip.py’ saved [2275758/2275758]\n",
            "\n",
            "Collecting pip\n",
            "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-75.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting wheel\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-75.3.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "Successfully installed pip-24.3.1 setuptools-75.3.0 wheel-0.45.1\n",
            "Collecting pip==24.0\n",
            "  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.3.1\n",
            "    Uninstalling pip-24.3.1:\n",
            "      Successfully uninstalled pip-24.3.1\n",
            "Successfully installed pip-24.0\n",
            "Collecting ipython\n",
            "  Downloading ipython-8.12.3-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting ipython_genutils\n",
            "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl.metadata (755 bytes)\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jupyter_console\n",
            "  Downloading jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting prompt_toolkit\n",
            "  Downloading prompt_toolkit-3.0.48-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: httplib2 in /usr/lib/python3/dist-packages (0.20.2)\n",
            "Collecting astor\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting backcall (from ipython)\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting decorator (from ipython)\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting jedi>=0.16 (from ipython)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting matplotlib-inline (from ipython)\n",
            "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pickleshare (from ipython)\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pygments>=2.4.0 (from ipython)\n",
            "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting stack-data (from ipython)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting traitlets>=5 (from ipython)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting typing-extensions (from ipython)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting pexpect>4.3 (from ipython)\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting comm>=0.1.1 (from ipykernel)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting debugpy>=1.6.5 (from ipykernel)\n",
            "  Downloading debugpy-1.8.9-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-core!=5.0.*,>=4.12 (from ipykernel)\n",
            "  Downloading jupyter_core-5.7.2-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting nest-asyncio (from ipykernel)\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting packaging (from ipykernel)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting psutil (from ipykernel)\n",
            "  Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting pyzmq>=24 (from ipykernel)\n",
            "  Downloading pyzmq-26.2.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting tornado>=6.1 (from ipykernel)\n",
            "  Downloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting wcwidth (from prompt_toolkit)\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/lib/python3/dist-packages (from httplib2) (2.4.7)\n",
            "Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython)\n",
            "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting importlib-metadata>=4.8.3 (from jupyter-client>=6.1.12->ipykernel)\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from jupyter-client>=6.1.12->ipykernel)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting platformdirs>=2.5 (from jupyter-core!=5.0.*,>=4.12->ipykernel)\n",
            "  Downloading platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython)\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting executing>=1.2.0 (from stack-data->ipython)\n",
            "  Downloading executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack-data->ipython)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pure-eval (from stack-data->ipython)\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting zipp>=3.20 (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel)\n",
            "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
            "Downloading ipython-8.12.3-py3-none-any.whl (798 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.3/798.3 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Downloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading prompt_toolkit-3.0.48-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading debugpy-1.8.9-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_core-5.7.2-py3-none-any.whl (28 kB)\n",
            "Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
            "Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyzmq-26.2.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (862 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.3/862.3 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.2/437.2 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.3/287.3 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading executing-2.1.0-py2.py3-none-any.whl (25 kB)\n",
            "Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.7/103.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading platformdirs-4.3.6-py3-none-any.whl (18 kB)\n",
            "Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
            "Installing collected packages: wcwidth, pure-eval, ptyprocess, pickleshare, ipython_genutils, backcall, zipp, typing-extensions, traitlets, tornado, pyzmq, python-dateutil, pygments, psutil, prompt_toolkit, platformdirs, pexpect, parso, packaging, nest-asyncio, executing, decorator, debugpy, asttokens, astor, stack-data, matplotlib-inline, jupyter-core, jedi, importlib-metadata, comm, jupyter-client, ipython, ipykernel, jupyter_console\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 1.0.0\n",
            "    Uninstalling zipp-1.0.0:\n",
            "      Successfully uninstalled zipp-1.0.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.6.4\n",
            "    Uninstalling importlib-metadata-4.6.4:\n",
            "      Successfully uninstalled importlib-metadata-4.6.4\n",
            "Successfully installed astor-0.8.1 asttokens-3.0.0 backcall-0.2.0 comm-0.2.2 debugpy-1.8.9 decorator-5.1.1 executing-2.1.0 importlib-metadata-8.5.0 ipykernel-6.29.5 ipython-8.12.3 ipython_genutils-0.2.0 jedi-0.19.2 jupyter-client-8.6.3 jupyter-core-5.7.2 jupyter_console-6.6.3 matplotlib-inline-0.1.7 nest-asyncio-1.6.0 packaging-24.2 parso-0.8.4 pexpect-4.9.0 pickleshare-0.7.5 platformdirs-4.3.6 prompt_toolkit-3.0.48 psutil-6.1.0 ptyprocess-0.7.0 pure-eval-0.2.3 pygments-2.18.0 python-dateutil-2.9.0.post0 pyzmq-26.2.0 stack-data-0.6.3 tornado-6.4.2 traitlets-5.14.3 typing-extensions-4.12.2 wcwidth-0.2.13 zipp-3.20.2\n"
          ]
        }
      ],
      "source": [
        "# install python 3.8\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.8\n",
        "\n",
        "# change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 2\n",
        "\n",
        "# check python version\n",
        "!python --version\n",
        "\n",
        "# install pip for new python\n",
        "!sudo apt-get install python3.8-distutils\n",
        "!wget https://bootstrap.pypa.io/get-pip.py\n",
        "!python get-pip.py\n",
        "\n",
        "!python -m pip install pip==24.0\n",
        "\n",
        "# credit of these last two commands blongs to @Erik\n",
        "# install colab's dependencies\n",
        "!python -m pip install ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor\n",
        "\n",
        "# link to the old google package\n",
        "!ln -s /usr/local/lib/python3.10/dist-packages/google \\\n",
        "       /usr/local/lib/python3.8/dist-packages/google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiebNAUDpxRc",
        "outputId": "4f374a2e-fbfd-4b28-9276-58943cf81677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.20\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtt8t23C1myS",
        "outputId": "5fd23de5-c348-4503-c7a7-31268d21a2f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec  2 14:43:51 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S9dNuLGlahK",
        "outputId": "f7a1b40c-e4cc-4b29-a823-c6b6c5abf435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'spacetimeformer'...\n",
            "remote: Enumerating objects: 661, done.\u001b[K\n",
            "remote: Counting objects: 100% (293/293), done.\u001b[K\n",
            "remote: Compressing objects: 100% (109/109), done.\u001b[K\n",
            "remote: Total 661 (delta 213), reused 203 (delta 184), pack-reused 368 (from 1)\u001b[K\n",
            "Receiving objects: 100% (661/661), 16.32 MiB | 15.03 MiB/s, done.\n",
            "Resolving deltas: 100% (351/351), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AlesSrsen/spacetimeformer.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1yDcAjxTm4qI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd73394-aec5-4cc4-b6ac-7af17195303b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "crypto_preparation.ipynb\tREADME.md\t  setup.py\n",
            "crypto_preparation_srsen.ipynb\treadme_media\t  spacetimeformer\n",
            "LICENSE\t\t\t\trequirements.txt  spacetimeformer_google_colab.ipynb\n"
          ]
        }
      ],
      "source": [
        "!cd /content/spacetimeformer\n",
        "!ls /content/spacetimeformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8w5vLVWm7TE",
        "outputId": "6caaabe6-57c1-4fb3-ffa8-0ea4677eb7a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Cython>=0.22 in /usr/local/lib/python3.10/dist-packages (from -r /content/spacetimeformer/requirements.txt (line 1)) (3.0.11)\n",
            "Collecting cmdstanpy==0.9.68 (from -r /content/spacetimeformer/requirements.txt (line 2))\n",
            "  Downloading cmdstanpy-0.9.68-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting pystan~=2.19.1.1 (from -r /content/spacetimeformer/requirements.txt (line 3))\n",
            "  Downloading pystan-2.19.1.1.tar.gz (16.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/spacetimeformer/requirements.txt (line 4)) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/spacetimeformer/requirements.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/spacetimeformer/requirements.txt (line 6)) (3.8.0)\n",
            "Collecting convertdate>=2.1.2 (from -r /content/spacetimeformer/requirements.txt (line 7))\n",
            "  Downloading convertdate-2.4.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/spacetimeformer/requirements.txt (line 8)) (2.8.2)\n",
            "Collecting performer-pytorch (from -r /content/spacetimeformer/requirements.txt (line 9))\n",
            "  Downloading performer_pytorch-1.1.4-py3-none-any.whl.metadata (763 bytes)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/spacetimeformer/requirements.txt (line 10)) (4.66.6)\n",
            "Collecting nystrom-attention (from -r /content/spacetimeformer/requirements.txt (line 11))\n",
            "  Downloading nystrom_attention-0.0.12-py3-none-any.whl.metadata (657 bytes)\n",
            "Collecting pytorch-lightning==1.6 (from -r /content/spacetimeformer/requirements.txt (line 12))\n",
            "  Downloading pytorch_lightning-1.6.0-py3-none-any.whl.metadata (33 kB)\n",
            "\u001b[33mWARNING: Ignoring version 1.6.0 of pytorch-lightning since it has invalid metadata:\n",
            "Requested pytorch-lightning==1.6 from https://files.pythonhosted.org/packages/09/18/cee67f4849dea9a29b7af7cdf582246bcba9eaa73d9443e138a4172ec786/pytorch_lightning-1.6.0-py3-none-any.whl (from -r /content/spacetimeformer/requirements.txt (line 12)) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    torch (>=1.8.*)\n",
            "           ~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch-lightning==1.6 (from versions: 0.0.2, 0.2, 0.2.2, 0.2.3, 0.2.4, 0.2.4.1, 0.2.5, 0.2.5.1, 0.2.5.2, 0.2.6, 0.3, 0.3.1, 0.3.2, 0.3.3, 0.3.4, 0.3.4.1, 0.3.5, 0.3.6, 0.3.6.1, 0.3.6.3, 0.3.6.4, 0.3.6.5, 0.3.6.6, 0.3.6.7, 0.3.6.8, 0.3.6.9, 0.4.0, 0.4.1, 0.4.2, 0.4.3, 0.4.4, 0.4.5, 0.4.6, 0.4.7, 0.4.8, 0.4.9, 0.5.0, 0.5.1, 0.5.1.2, 0.5.1.3, 0.5.2, 0.5.2.1, 0.5.3, 0.5.3.1, 0.5.3.2, 0.5.3.3, 0.6.0, 0.7.1, 0.7.3, 0.7.5, 0.7.6, 0.8.1, 0.8.3, 0.8.4, 0.8.5, 0.9.0, 0.10.0, 1.0.0, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.0.5, 1.0.6, 1.0.7, 1.0.8, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.1.4, 1.1.5, 1.1.6, 1.1.7, 1.1.8, 1.2.0rc0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.2.4, 1.2.5, 1.2.6, 1.2.7, 1.2.8, 1.2.9, 1.2.10, 1.3.0rc1, 1.3.0rc2, 1.3.0rc3, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.3.4, 1.3.5, 1.3.6, 1.3.7, 1.3.7.post0, 1.3.8, 1.4.0rc0, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.4.2, 1.4.3, 1.4.4, 1.4.5, 1.4.6, 1.4.7, 1.4.8, 1.4.9, 1.5.0rc0, 1.5.0rc1, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 1.5.4, 1.5.5, 1.5.6, 1.5.7, 1.5.8, 1.5.9, 1.5.10, 1.6.0rc0, 1.6.0rc1, 1.6.0, 1.6.1, 1.6.2, 1.6.3, 1.6.4, 1.6.5, 1.7.0rc0, 1.7.0rc1, 1.7.0, 1.7.1, 1.7.2, 1.7.3, 1.7.4, 1.7.5, 1.7.6, 1.7.7, 1.8.0rc0, 1.8.0rc1, 1.8.0rc2, 1.8.0, 1.8.0.post1, 1.8.1, 1.8.2, 1.8.3, 1.8.3.post0, 1.8.3.post1, 1.8.3.post2, 1.8.4, 1.8.4.post0, 1.8.5, 1.8.5.post0, 1.8.6, 1.9.0rc0, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.9.4, 1.9.5, 2.0.0rc0, 2.0.0, 2.0.1, 2.0.1.post0, 2.0.2, 2.0.3, 2.0.4, 2.0.5, 2.0.6, 2.0.7, 2.0.8, 2.0.9, 2.0.9.post0, 2.1.0rc0, 2.1.0rc1, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.2.0rc0, 2.2.0, 2.2.0.post0, 2.2.1, 2.2.2, 2.2.3, 2.2.4, 2.2.5, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.4.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pytorch-lightning==1.6\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.4.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp310-cp310-linux_x86_64.whl (798.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.9/798.9 MB\u001b[0m \u001b[31m797.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.19.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp310-cp310-linux_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.4.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19.1) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19.1) (11.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.5.1+cu121\n",
            "    Uninstalling torchaudio-2.5.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.5.1+cu121\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.1+cu121 torchaudio-2.4.1+cu121 torchvision-0.19.1+cu121 triton-3.0.0\n"
          ]
        }
      ],
      "source": [
        "# DO NOT RESTART THE RUNTIME - IT BREAKS THE PYTHON 3.8 The runtime may not even start\n",
        "%pip install -r /content/spacetimeformer/requirements.txt\n",
        "%pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJCLT0lnp1ul",
        "outputId": "6737ddaa-b816-40f9-f90c-41db38c93ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./spacetimeformer\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: spacetimeformer\n",
            "  Building wheel for spacetimeformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spacetimeformer: filename=spacetimeformer-1.5.0-py3-none-any.whl size=95649 sha256=91b8682948c97d797d0ee8aeb00f2fd214baa290760fbfd169f6bb2ee3ffd5fa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-r1d909uj/wheels/7c/50/8b/5ddea8d5fbf5266363fe25364df45b57c105c646f99b175bc6\n",
            "Successfully built spacetimeformer\n",
            "Installing collected packages: spacetimeformer\n",
            "Successfully installed spacetimeformer-1.5.0\n"
          ]
        }
      ],
      "source": [
        "%pip install /content/spacetimeformer/\n",
        "# If editable then\n",
        "# !pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_T9xxB-dZVr",
        "outputId": "113d8823-ba9d-4553-daed-39c409ef0912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unIvJ_kikMDM",
        "outputId": "4be1e294-175b-4237-f202-3c06084d5d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2oaTh2_XRH-"
      },
      "source": [
        "# Pull and update content from the repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP9uqIm1kIGt",
        "outputId": "18dd6adc-7892-4558-e061-3dcf59320ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/AlesSrsen/spacetimeformer\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!cd /content/spacetimeformer/ && git pull origin main\n",
        "!cd /content/spacetimeformer && git checkout main -- spacetimeformer/train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRp_0gjfkX29"
      },
      "outputs": [],
      "source": [
        "#!cat /content/spacetimeformer/spacetimeformer/train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHWU_YR8dpZ5",
        "outputId": "7ef42c79-e95f-49f2-d6cb-bce0a8c02b4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/drive/MyDrive/ColabNotebooks/DataminingAndTimeSeries': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/ColabNotebooks/DataminingAndTimeSeries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Gowo_Heb7DI",
        "outputId": "b54faf10-da98-4a43-d2e6-5f7c48215cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: STF_WANDB_ACCT=johannes_thyroff\n",
            "env: STF_WANDB_PROJ=DataminingAndTimeseries\n",
            "env: STF_LOG_DIR=/content/drive/MyDrive/ColabNotebooks/DataminingAndTimeSeries/wandb/\n"
          ]
        }
      ],
      "source": [
        "%env STF_WANDB_ACCT=johannes_thyroff\n",
        "%env STF_WANDB_PROJ=DataminingAndTimeseries\n",
        "%env STF_LOG_DIR=/content/drive/MyDrive/ColabNotebooks/DataminingAndTimeSeries/wandb/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcglmHbR_QIi",
        "outputId": "792432c6-6f26-42e8-8c34-1bd29bc0b687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!wandb login --relogin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_ZK9X99xBrC",
        "outputId": "a8a8bd90-6ad5-4d26-8692-93e9f22ed1ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "johannes_thyroff\n",
            "DataminingAndTimeseries\n",
            "Username and projectname have to be without \" . \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjohannes_thyroff\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/ColabNotebooks/DataminingAndTimeSeries/wandb/wandb/run-20241201_101801-zpx3bqau\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlaced-lake-12\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/johannes_thyroff/DataminingAndTimeseries\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/johannes_thyroff/DataminingAndTimeseries/runs/zpx3bqau\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/core/lightning.py:2046: DeprecationWarning: `torch.distributed._sharded_tensor` will be deprecated, use `torch.distributed._shard.sharded_tensor` instead\n",
            "  from torch.distributed._sharded_tensor import pre_load_state_dict_hook, state_dict_hook\n",
            "Forecaster\n",
            "\tL2: 1e-06\n",
            "\tLinear Window: 0\n",
            "\tLinear Shared Weights: False\n",
            "\tRevIN: False\n",
            "\tDecomposition: False\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:287: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
            "  rank_zero_deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/utilities.py:91: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
            "  rank_zero_warn(\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name    | Type         | Params\n",
            "-----------------------------------------\n",
            "0 | t2v     | Time2Vec     | 288   \n",
            "1 | encoder | LSTM_Encoder | 272 K \n",
            "2 | decoder | LSTM_Decoder | 273 K \n",
            "3 | model   | LSTM_Seq2Seq | 546 K \n",
            "-----------------------------------------\n",
            "546 K     Trainable params\n",
            "0         Non-trainable params\n",
            "546 K     Total params\n",
            "2.185     Total estimated model params size (MB)\n",
            "Sanity Checking: 0it [00:00, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Sanity Checking DataLoader 0:   0% 0/2 [00:00<?, ?it/s]Traceback (most recent call last):\n",
            "  File \"/content/spacetimeformer/spacetimeformer/train.py\", line 879, in <module>\n",
            "    main(args)\n",
            "  File \"/content/spacetimeformer/spacetimeformer/train.py\", line 859, in main\n",
            "    trainer.fit(forecaster, datamodule=data_module)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\", line 771, in fit\n",
            "    self._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\", line 724, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\", line 812, in _fit_impl\n",
            "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1237, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1324, in _run_stage\n",
            "    return self._run_train()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1346, in _run_train\n",
            "    self._run_sanity_check()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1414, in _run_sanity_check\n",
            "    val_loop.run()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/base.py\", line 204, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 153, in advance\n",
            "    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/base.py\", line 204, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 127, in advance\n",
            "    output = self._evaluation_step(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 222, in _evaluation_step\n",
            "    output = self.trainer._call_strategy_hook(\"validation_step\", *kwargs.values())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1766, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/strategies/dp.py\", line 129, in validation_step\n",
            "    return self.model(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/data_parallel.py\", line 184, in forward\n",
            "    return self.module(*inputs[0], **module_kwargs[0])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/overrides/data_parallel.py\", line 64, in forward\n",
            "    output = super().forward(*inputs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/overrides/base.py\", line 93, in forward\n",
            "    return self.module.validation_step(*inputs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/spacetimeformer/forecaster.py\", line 256, in validation_step\n",
            "    stats = self.step(batch, train=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/spacetimeformer/forecaster.py\", line 242, in step\n",
            "    loss, output, mask = self.compute_loss(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/spacetimeformer/forecaster.py\", line 134, in compute_loss\n",
            "    outputs, *_ = self(x_c, y_c, x_t, y_t, **forward_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/spacetimeformer/forecaster.py\", line 204, in forward\n",
            "    preds, *extra = self.forward_model_pass(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/spacetimeformer/lstm_model/lstm_model.py\", line 171, in forward_model_pass\n",
            "    preds = self.model.forward(x_c, y_c, x_t, y_t, teacher_forcing_prob=force)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/spacetimeformer/lstm_model/lstm_model.py\", line 74, in forward\n",
            "    x_context = self.t2v(x_context)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/spacetimeformer/time2vec.py\", line 25, in forward\n",
            "    x_affine = torch.matmul(x, self.embed_weight) + self.embed_bias\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (1440x6 and 12x12)\n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mlaced-lake-12\u001b[0m at: \u001b[34mhttps://wandb.ai/johannes_thyroff/DataminingAndTimeseries/runs/zpx3bqau\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mdrive/MyDrive/ColabNotebooks/DataminingAndTimeSeries/wandb/wandb/run-20241201_101801-zpx3bqau/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# use --gpus 0\n",
        "# https://github.com/QData/spacetimeformer/issues/90#issuecomment-2220829221\n",
        "# Github Save Change\n",
        "\n",
        "#--time_emb_dim\n",
        "\n",
        "# TODO\n",
        "!echo $STF_WANDB_ACCT\n",
        "!echo $STF_WANDB_PROJ\n",
        "print('Username and projectname have to be without \" . ')\n",
        "#\n",
        "!WANDB_API_KEY=YourApiKeyd; python /content/spacetimeformer/spacetimeformer/train.py lstm dmts_crypto --data_path /content/drive/MyDrive/ColabNotebooks/DataminingAndTimeSeries/debug_12_cols_500_rows_noNaN_eth_timeseries.csv --wandb --batch_size 24 --run_name dmts_lstm_stf --context_points 10  --gpus 0\n",
        "\n",
        "\n",
        "#\n",
        "# Run spacetimeformer\n",
        "#\n",
        "# python /content/spacetimeformer/spacetimeformer/train.py spacetimeformer dmts_crypto --data_path /content/drive/MyDrive/ColabNotebooks/DataminingAndTimeSeries/debug_12_cols_500_rows_noNaN_eth_timeseries.csv --wandb --batch_size 24 --embed_method spatio-temporal --local_self_attn full --local_cross_attn full --global_self_attn full --global_cross_attn full --run_name dmts_spatio_temporal_stf --context_points 10  --gpus 0\n",
        "#\n",
        "\n",
        "#\n",
        "# Run spacetimeformer only with temporal attention. Figure 2b from the paper\n",
        "#\n",
        "# The following three parameters are changed: --embed_method temporal --local_self_attn none --local_cross_attn none\n",
        "#\n",
        "# python /content/spacetimeformer/spacetimeformer/train.py spacetimeformer dmts_crypto --data_path /content/drive/MyDrive/ColabNotebooks/DataminingAndTimeSeries/debug_12_cols_500_rows_noNaN_eth_timeseries.csv --wandb --batch_size 24 --embed_method temporal --local_self_attn none --local_cross_attn none --global_self_attn full --global_cross_attn full --run_name dmts_temporal_stf --context_points 10  --gpus 0\n",
        "#\n",
        "\n",
        "#\n",
        "# Run LSTM forecaster\n",
        "# python /content/spacetimeformer/spacetimeformer/train.py lstm dmts_crypto --data_path /content/drive/MyDrive/ColabNotebooks/DataminingAndTimeSeries/debug_12_cols_500_rows_noNaN_eth_timeseries.csv --wandb --batch_size 24 --run_name dmts_lstm_stf --context_points 10  --gpus 0\n",
        "#\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke2TVsU5ocuZ"
      },
      "source": [
        "# Training code\n",
        "Code below is extracted code from train.py made to work in colab without calling the command line. This gives us the ability to easily adjust the code and run it in colab."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: upload file\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n"
      ],
      "metadata": {
        "id": "eLePS7VV19Vg",
        "outputId": "539dfa5d-d69c-463d-84eb-c2c1ce97419f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-978724e7-e5f7-4546-939d-c9b8c15da5ab\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-978724e7-e5f7-4546-939d-c9b8c15da5ab\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving preprocessed_12_cols_500_rows_noNaN_eth_timeseries.csv to preprocessed_12_cols_500_rows_noNaN_eth_timeseries.csv\n",
            "User uploaded file \"preprocessed_12_cols_500_rows_noNaN_eth_timeseries.csv\" with length 70617 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: check which version of python is running in code\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.version"
      ],
      "metadata": {
        "id": "v1fPg-r63OMD",
        "outputId": "a317bbea-3d9b-434e-a22b-7d61eba96cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pytorch-lightning==1.9.0 netCDF4 omegaconf performer_pytorch"
      ],
      "metadata": {
        "id": "4tENYA7I5CLm",
        "outputId": "6f16fe2f-f4a7-4601-c21d-16c346a983e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-lightning==1.9.0 in /usr/local/lib/python3.10/dist-packages (1.9.0)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Collecting performer_pytorch\n",
            "  Using cached performer_pytorch-1.1.4-py3-none-any.whl.metadata (763 bytes)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0) (4.66.6)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0) (6.0.2)\n",
            "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (2024.10.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0) (1.6.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0) (4.12.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0) (0.11.9)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.10/dist-packages (from netCDF4) (1.6.4.post1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from netCDF4) (2024.8.30)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: einops>=0.3 in /usr/local/lib/python3.10/dist-packages (from performer_pytorch) (0.8.0)\n",
            "Collecting local-attention>=1.1.1 (from performer_pytorch)\n",
            "  Downloading local_attention-1.9.15-py3-none-any.whl.metadata (683 bytes)\n",
            "Collecting axial-positional-embedding>=0.1.0 (from performer_pytorch)\n",
            "  Downloading axial_positional_embedding-0.2.1.tar.gz (2.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (3.11.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.4.2->pytorch-lightning==1.9.0) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->pytorch-lightning==1.9.0) (12.6.77)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->pytorch-lightning==1.9.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->pytorch-lightning==1.9.0) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (3.10)\n",
            "Downloading performer_pytorch-1.1.4-py3-none-any.whl (13 kB)\n",
            "Downloading local_attention-1.9.15-py3-none-any.whl (9.0 kB)\n",
            "Building wheels for collected packages: axial-positional-embedding\n",
            "  Building wheel for axial-positional-embedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axial-positional-embedding: filename=axial_positional_embedding-0.2.1-py3-none-any.whl size=2887 sha256=6d0262cb6aa7d468e3f19c5cbeef81b4c40357e3b5162acd9192935dbf61a2b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/cb/39/7ce7ff2d2fd37cfe1fe7b3a3c43cf410632b2ad3b3f3986d73\n",
            "Successfully built axial-positional-embedding\n",
            "Installing collected packages: local-attention, axial-positional-embedding, performer_pytorch\n",
            "Successfully installed axial-positional-embedding-0.2.1 local-attention-1.9.15 performer_pytorch-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "HPlTToeXTDDK"
      },
      "outputs": [],
      "source": [
        "from argparse import ArgumentParser\n",
        "import os\n",
        "import uuid\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import spacetimeformer as stf\n",
        "\n",
        "_MODELS = [\"spacetimeformer\", \"mtgnn\", \"heuristic\", \"lstm\", \"lstnet\", \"linear\", \"s4\"]\n",
        "\n",
        "\n",
        "def create_adjusted_parser(model):\n",
        "    # Throw error now before we get confusing parser issues\n",
        "    assert (\n",
        "        model in _MODELS\n",
        "    ), f\"Unrecognized model (`{model}`). Options include: {_MODELS}\"\n",
        "\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument(\"model\")\n",
        "    parser.add_argument(\"dset\")\n",
        "\n",
        "    stf.data.CSVTimeSeries.add_cli(parser)\n",
        "    stf.data.CSVTorchDset.add_cli(parser)\n",
        "\n",
        "    stf.data.DataModule.add_cli(parser)\n",
        "\n",
        "    if model == \"lstm\":\n",
        "        stf.lstm_model.LSTM_Forecaster.add_cli(parser)\n",
        "        stf.callbacks.TeacherForcingAnnealCallback.add_cli(parser)\n",
        "    elif model == \"lstnet\":\n",
        "        stf.lstnet_model.LSTNet_Forecaster.add_cli(parser)\n",
        "    elif model == \"mtgnn\":\n",
        "        stf.mtgnn_model.MTGNN_Forecaster.add_cli(parser)\n",
        "    elif model == \"heuristic\":\n",
        "        stf.heuristic_model.Heuristic_Forecaster.add_cli(parser)\n",
        "    elif model == \"spacetimeformer\":\n",
        "        stf.spacetimeformer_model.Spacetimeformer_Forecaster.add_cli(parser)\n",
        "    elif model == \"linear\":\n",
        "        stf.linear_model.Linear_Forecaster.add_cli(parser)\n",
        "    elif model == \"s4\":\n",
        "        stf.s4_model.S4_Forecaster.add_cli(parser)\n",
        "\n",
        "    stf.callbacks.TimeMaskedLossCallback.add_cli(parser)\n",
        "\n",
        "    parser.add_argument(\"--wandb\", action=\"store_true\")\n",
        "    parser.add_argument(\"--plot\", action=\"store_true\")\n",
        "    parser.add_argument(\"--plot_samples\", type=int, default=8)\n",
        "    parser.add_argument(\"--attn_plot\", action=\"store_true\")\n",
        "    parser.add_argument(\"--debug\", action=\"store_true\")\n",
        "    parser.add_argument(\"--run_name\", type=str, required=True)\n",
        "    parser.add_argument(\"--accumulate\", type=int, default=1)\n",
        "    parser.add_argument(\"--val_check_interval\", type=float, default=1.0)\n",
        "    parser.add_argument(\"--limit_val_batches\", type=float, default=1.0)\n",
        "    parser.add_argument(\"--no_earlystopping\", action=\"store_true\")\n",
        "    parser.add_argument(\"--patience\", type=int, default=5)\n",
        "    parser.add_argument(\n",
        "        \"--trials\", type=int, default=1, help=\"How many consecutive trials to run\"\n",
        "    )\n",
        "\n",
        "    return parser\n",
        "\n",
        "\n",
        "def create_model(config):\n",
        "    x_dim, yc_dim, yt_dim = None, None, None\n",
        "    if config.dset == \"dmts_crypto\":\n",
        "        x_dim = 6\n",
        "        yc_dim = 1\n",
        "        yt_dim = 1\n",
        "    assert x_dim is not None\n",
        "    assert yc_dim is not None\n",
        "    assert yt_dim is not None\n",
        "\n",
        "    print(f'Using x_dim={x_dim} yc_dim={yc_dim} yt_dim={yt_dim}')\n",
        "\n",
        "    if config.model == \"lstm\":\n",
        "        forecaster = stf.lstm_model.LSTM_Forecaster(\n",
        "            # encoder\n",
        "            d_x=x_dim,\n",
        "            d_yc=yc_dim,\n",
        "            d_yt=yt_dim,\n",
        "            time_emb_dim=config.time_emb_dim,\n",
        "            hidden_dim=config.hidden_dim,\n",
        "            n_layers=config.n_layers,\n",
        "            dropout_p=config.dropout_p,\n",
        "            # training\n",
        "            learning_rate=config.learning_rate,\n",
        "            teacher_forcing_prob=config.teacher_forcing_start,\n",
        "            l2_coeff=config.l2_coeff,\n",
        "            loss=config.loss,\n",
        "            linear_window=config.linear_window,\n",
        "            use_revin=config.use_revin,\n",
        "            linear_shared_weights=config.linear_shared_weights,\n",
        "            use_seasonal_decomp=config.use_seasonal_decomp,\n",
        "        )\n",
        "\n",
        "    elif config.model == \"heuristic\":\n",
        "        forecaster = stf.heuristic_model.Heuristic_Forecaster(\n",
        "            d_x=x_dim,\n",
        "            d_yc=yc_dim,\n",
        "            d_yt=yt_dim,\n",
        "            context_points=config.context_points,\n",
        "            target_points=config.target_points,\n",
        "            loss=config.loss,\n",
        "            method=config.method,\n",
        "        )\n",
        "    elif config.model == \"mtgnn\":\n",
        "        forecaster = stf.mtgnn_model.MTGNN_Forecaster(\n",
        "            d_x=x_dim,\n",
        "            d_yc=yc_dim,\n",
        "            d_yt=yt_dim,\n",
        "            context_points=config.context_points,\n",
        "            target_points=config.target_points,\n",
        "            gcn_depth=config.gcn_depth,\n",
        "            dropout_p=config.dropout_p,\n",
        "            node_dim=config.node_dim,\n",
        "            dilation_exponential=config.dilation_exponential,\n",
        "            conv_channels=config.conv_channels,\n",
        "            subgraph_size=config.subgraph_size,\n",
        "            skip_channels=config.skip_channels,\n",
        "            end_channels=config.end_channels,\n",
        "            residual_channels=config.residual_channels,\n",
        "            layers=config.layers,\n",
        "            propalpha=config.propalpha,\n",
        "            tanhalpha=config.tanhalpha,\n",
        "            learning_rate=config.learning_rate,\n",
        "            kernel_size=config.kernel_size,\n",
        "            l2_coeff=config.l2_coeff,\n",
        "            time_emb_dim=config.time_emb_dim,\n",
        "            loss=config.loss,\n",
        "            linear_window=config.linear_window,\n",
        "            linear_shared_weights=config.linear_shared_weights,\n",
        "            use_seasonal_decomp=config.use_seasonal_decomp,\n",
        "            use_revin=config.use_revin,\n",
        "        )\n",
        "    elif config.model == \"lstnet\":\n",
        "        forecaster = stf.lstnet_model.LSTNet_Forecaster(\n",
        "            d_x=x_dim,\n",
        "            d_yc=yc_dim,\n",
        "            d_yt=yt_dim,\n",
        "            context_points=config.context_points,\n",
        "            hidRNN=config.hidRNN,\n",
        "            hidCNN=config.hidCNN,\n",
        "            hidSkip=config.hidSkip,\n",
        "            CNN_kernel=config.CNN_kernel,\n",
        "            skip=config.skip,\n",
        "            dropout_p=config.dropout_p,\n",
        "            output_fun=config.output_fun,\n",
        "            learning_rate=config.learning_rate,\n",
        "            l2_coeff=config.l2_coeff,\n",
        "            loss=config.loss,\n",
        "            linear_window=config.linear_window,\n",
        "            use_revin=config.use_revin,\n",
        "        )\n",
        "    elif config.model == \"spacetimeformer\":\n",
        "        if hasattr(config, \"context_points\") and hasattr(config, \"target_points\"):\n",
        "            max_seq_len = config.context_points + config.target_points\n",
        "        elif hasattr(config, \"max_len\"):\n",
        "            max_seq_len = config.max_len\n",
        "        else:\n",
        "            raise ValueError(\"Undefined max_seq_len\")\n",
        "        forecaster = stf.spacetimeformer_model.Spacetimeformer_Forecaster(\n",
        "            d_x=x_dim,\n",
        "            d_yc=yc_dim,\n",
        "            d_yt=yt_dim,\n",
        "            max_seq_len=max_seq_len,\n",
        "            start_token_len=config.start_token_len,\n",
        "            attn_factor=config.attn_factor,\n",
        "            d_model=config.d_model,\n",
        "            d_queries_keys=config.d_qk,\n",
        "            d_values=config.d_v,\n",
        "            n_heads=config.n_heads,\n",
        "            e_layers=config.enc_layers,\n",
        "            d_layers=config.dec_layers,\n",
        "            d_ff=config.d_ff,\n",
        "            dropout_emb=config.dropout_emb,\n",
        "            dropout_attn_out=config.dropout_attn_out,\n",
        "            dropout_attn_matrix=config.dropout_attn_matrix,\n",
        "            dropout_qkv=config.dropout_qkv,\n",
        "            dropout_ff=config.dropout_ff,\n",
        "            pos_emb_type=config.pos_emb_type,\n",
        "            use_final_norm=not config.no_final_norm,\n",
        "            global_self_attn=config.global_self_attn,\n",
        "            local_self_attn=config.local_self_attn,\n",
        "            global_cross_attn=config.global_cross_attn,\n",
        "            local_cross_attn=config.local_cross_attn,\n",
        "            performer_kernel=config.performer_kernel,\n",
        "            performer_redraw_interval=config.performer_redraw_interval,\n",
        "            attn_time_windows=config.attn_time_windows,\n",
        "            use_shifted_time_windows=config.use_shifted_time_windows,\n",
        "            norm=config.norm,\n",
        "            activation=config.activation,\n",
        "            init_lr=config.init_lr,\n",
        "            base_lr=config.base_lr,\n",
        "            warmup_steps=config.warmup_steps,\n",
        "            decay_factor=config.decay_factor,\n",
        "            initial_downsample_convs=config.initial_downsample_convs,\n",
        "            intermediate_downsample_convs=config.intermediate_downsample_convs,\n",
        "            embed_method=config.embed_method,\n",
        "            l2_coeff=config.l2_coeff,\n",
        "            loss=config.loss,\n",
        "            class_loss_imp=config.class_loss_imp,\n",
        "            recon_loss_imp=config.recon_loss_imp,\n",
        "            time_emb_dim=config.time_emb_dim,\n",
        "            null_value=config.null_value,\n",
        "            pad_value=config.pad_value,\n",
        "            linear_window=config.linear_window,\n",
        "            use_revin=config.use_revin,\n",
        "            linear_shared_weights=config.linear_shared_weights,\n",
        "            use_seasonal_decomp=config.use_seasonal_decomp,\n",
        "            use_val=not config.no_val,\n",
        "            use_time=not config.no_time,\n",
        "            use_space=not config.no_space,\n",
        "            use_given=not config.no_given,\n",
        "            recon_mask_skip_all=config.recon_mask_skip_all,\n",
        "            recon_mask_max_seq_len=config.recon_mask_max_seq_len,\n",
        "            recon_mask_drop_seq=config.recon_mask_drop_seq,\n",
        "            recon_mask_drop_standard=config.recon_mask_drop_standard,\n",
        "            recon_mask_drop_full=config.recon_mask_drop_full,\n",
        "        )\n",
        "    elif config.model == \"linear\":\n",
        "        forecaster = stf.linear_model.Linear_Forecaster(\n",
        "            d_x=x_dim,\n",
        "            d_yc=yc_dim,\n",
        "            d_yt=yt_dim,\n",
        "            context_points=config.context_points,\n",
        "            learning_rate=config.learning_rate,\n",
        "            l2_coeff=config.l2_coeff,\n",
        "            loss=config.loss,\n",
        "            linear_window=config.linear_window,\n",
        "            linear_shared_weights=config.linear_shared_weights,\n",
        "            use_revin=config.use_revin,\n",
        "            use_seasonal_decomp=config.use_seasonal_decomp,\n",
        "        )\n",
        "    elif config.model == \"s4\":\n",
        "        forecaster = stf.s4_model.S4_Forecaster(\n",
        "            context_points=config.context_points,\n",
        "            target_points=config.target_points,\n",
        "            d_state=config.d_state,\n",
        "            d_model=config.d_model,\n",
        "            d_x=x_dim,\n",
        "            d_yc=yc_dim,\n",
        "            d_yt=yt_dim,\n",
        "            layers=config.layers,\n",
        "            time_emb_dim=config.time_emb_dim,\n",
        "            channels=config.channels,\n",
        "            dropout_p=config.dropout_p,\n",
        "            learning_rate=config.learning_rate,\n",
        "            l2_coeff=config.l2_coeff,\n",
        "            loss=config.loss,\n",
        "            linear_window=config.linear_window,\n",
        "            linear_shared_weights=config.linear_shared_weights,\n",
        "            use_revin=config.use_revin,\n",
        "            use_seasonal_decomp=config.use_seasonal_decomp,\n",
        "        )\n",
        "\n",
        "    return forecaster\n",
        "\n",
        "\n",
        "def create_dset(config):\n",
        "    INV_SCALER = lambda x: x\n",
        "    SCALER = lambda x: x\n",
        "    NULL_VAL = None\n",
        "    PLOT_VAR_IDXS = None\n",
        "    PLOT_VAR_NAMES = None\n",
        "    PAD_VAL = None\n",
        "\n",
        "    time_col_name = \"Datetime\"\n",
        "    data_path = config.data_path\n",
        "    time_features = [\"year\", \"month\", \"day\", \"weekday\", \"hour\", \"minute\"]\n",
        "\n",
        "    if config.dset == \"dmts_crypto\":  # DMTS Modification\n",
        "        if data_path == \"auto\":\n",
        "            raise ValueError(\"Please specify a datapath.\")\n",
        "        target_cols = [\"close\"]\n",
        "        time_col_name = \"time\"\n",
        "\n",
        "    dset = stf.data.CSVTimeSeries(\n",
        "        data_path=data_path,\n",
        "        target_cols=target_cols,\n",
        "        ignore_cols=\"all\",\n",
        "        time_col_name=time_col_name,\n",
        "        time_features=time_features,\n",
        "        val_split=0.2,\n",
        "        test_split=0.2,\n",
        "    )\n",
        "    DATA_MODULE = stf.data.DataModule(\n",
        "        datasetCls=stf.data.CSVTorchDset,\n",
        "        dataset_kwargs={\n",
        "            \"csv_time_series\": dset,\n",
        "            \"context_points\": config.context_points,\n",
        "            \"target_points\": config.target_points,\n",
        "            \"time_resolution\": config.time_resolution,\n",
        "        },\n",
        "        batch_size=config.batch_size,\n",
        "        workers=config.workers,\n",
        "        overfit=config.overfit,\n",
        "    )\n",
        "    INV_SCALER = dset.reverse_scaling\n",
        "    SCALER = dset.apply_scaling\n",
        "    NULL_VAL = None\n",
        "\n",
        "    return (\n",
        "        DATA_MODULE,\n",
        "        INV_SCALER,\n",
        "        SCALER,\n",
        "        NULL_VAL,\n",
        "        PLOT_VAR_IDXS,\n",
        "        PLOT_VAR_NAMES,\n",
        "        PAD_VAL,\n",
        "    )\n",
        "\n",
        "\n",
        "def create_callbacks(config, save_dir):\n",
        "    filename = f\"{config.run_name}_\" + str(uuid.uuid1()).split(\"-\")[0]\n",
        "    model_ckpt_dir = os.path.join(save_dir, filename)\n",
        "    config.model_ckpt_dir = model_ckpt_dir\n",
        "    saving = pl.callbacks.ModelCheckpoint(\n",
        "        dirpath=model_ckpt_dir,\n",
        "        monitor=\"val/loss\",\n",
        "        mode=\"min\",\n",
        "        filename=f\"{config.run_name}\" + \"{epoch:02d}\",\n",
        "        save_top_k=1,\n",
        "        auto_insert_metric_name=True,\n",
        "    )\n",
        "    callbacks = [saving]\n",
        "\n",
        "    if not config.no_earlystopping:\n",
        "        callbacks.append(\n",
        "            pl.callbacks.early_stopping.EarlyStopping(\n",
        "                monitor=\"val/loss\",\n",
        "                patience=config.patience,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    if config.wandb:\n",
        "        callbacks.append(pl.callbacks.LearningRateMonitor())\n",
        "\n",
        "    if config.model == \"lstm\":\n",
        "        callbacks.append(\n",
        "            stf.callbacks.TeacherForcingAnnealCallback(\n",
        "                start=config.teacher_forcing_start,\n",
        "                end=config.teacher_forcing_end,\n",
        "                steps=config.teacher_forcing_anneal_steps,\n",
        "            )\n",
        "        )\n",
        "    if config.time_mask_loss:\n",
        "        callbacks.append(\n",
        "            stf.callbacks.TimeMaskedLossCallback(\n",
        "                start=config.time_mask_start,\n",
        "                end=config.time_mask_end,\n",
        "                steps=config.time_mask_anneal_steps,\n",
        "            )\n",
        "        )\n",
        "    return callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "em86vL0Eocuf"
      },
      "outputs": [],
      "source": [
        "# Training setup\n",
        "STF_WANDB_ACCT = \"johannes_thyroff\"\n",
        "STF_WANDB_PROJ = \"DataminingAndTimeseries\"\n",
        "STF_LOG_DIR = \"/content/drive/MyDrive/ColabNotebooks/DataminingAndTimeSeries/wandb/\"\n",
        "\n",
        "DATASET_PATH='/content/preprocessed_12_cols_500_rows_noNaN_eth_timeseries.csv'\n",
        "\n",
        "ARGS_SPACETIMEFORMER = [\n",
        "        \"spacetimeformer\",\n",
        "        \"dmts_crypto\",\n",
        "        \"--data_path\",\n",
        "        DATASET_PATH,\n",
        "        # \"--wandb\",\n",
        "        \"--batch_size\",\n",
        "        \"24\",\n",
        "        \"--embed_method\",\n",
        "        \"spatio-temporal\",\n",
        "        \"--local_self_attn\",\n",
        "        \"full\",\n",
        "        \"--local_cross_attn\",\n",
        "        \"full\",\n",
        "        \"--global_self_attn\",\n",
        "        \"full\",\n",
        "        \"--global_cross_attn\",\n",
        "        \"full\",\n",
        "        \"--run_name\",\n",
        "        \"dmts_first_run_stf\",\n",
        "        \"--context_points\",\n",
        "        \"10\",\n",
        "        \"--gpus\",\n",
        "        \"0\",\n",
        "    ]\n",
        "\n",
        "ARGS_LSTM = [\n",
        "    \"lstm\",\n",
        "    \"dmts_crypto\",\n",
        "    \"--data_path\",\n",
        "    DATASET_PATH,\n",
        "    # \"--wandb\",\n",
        "    \"--batch_size\",\n",
        "    \"24\",\n",
        "    \"--run_name\",\n",
        "    \"dmts_lstm_stf\",\n",
        "    \"--context_points\",\n",
        "    \"10\",\n",
        "    \"--gpus\",\n",
        "    \"0\",\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ARGS=ARGS_SPACETIMEFORMER\n",
        "MODEL=ARGS[0]\n",
        "\n",
        "\n",
        "ARG_CONFIG = create_adjusted_parser(MODEL).parse_args(\n",
        "    ARGS\n",
        ")"
      ],
      "metadata": {
        "id": "WJfFux6q7a6d"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "UFafU1prUnhg",
        "outputId": "907fb09d-4a45-4a92-95b8-dba3bbc6a510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bd9025f66b184c21aee13069a5b63cf8",
            "6b2b7854fb5d43df9c588babdd47765c",
            "b3cd7f114a5d4d46bf08c0431a739a4b",
            "fcbaa5644b934102a4cee15b07dc4455",
            "3f52110e9f5d4eb08f4b59d98fd0d9ae",
            "ec1adbfa9a8140129260514c8cbd8a28",
            "1d5f79b350e64fd98d6770be4a588107",
            "7864a0b6ac9144038845de640fee4da2",
            "baf018ef05054c72a3addbbce76b75f8",
            "60437c4fd3184227bf9a8cc684d61fa7",
            "e8d56a503f6040d88643bd95c8483380"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacetimeformer/data/timefeatures.py:24: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
            "  main_df[\"Month\"] = dates.apply(\n",
            "/usr/local/lib/python3.10/dist-packages/spacetimeformer/data/timefeatures.py:28: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
            "  main_df[\"Day\"] = dates.apply(lambda row: 2.0 * ((row.day - 1) / 30.0) - 1.0, 1)\n",
            "/usr/local/lib/python3.10/dist-packages/spacetimeformer/data/timefeatures.py:30: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
            "  main_df[\"Weekday\"] = dates.apply(\n",
            "/usr/local/lib/python3.10/dist-packages/spacetimeformer/data/timefeatures.py:34: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
            "  main_df[\"Hour\"] = dates.apply(lambda row: 2.0 * ((row.hour) / 23.0) - 1.0, 1)\n",
            "/usr/local/lib/python3.10/dist-packages/spacetimeformer/data/timefeatures.py:36: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
            "  main_df[\"Minute\"] = dates.apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using x_dim=6 yc_dim=1 yt_dim=1\n",
            "Forecaster\n",
            "\tL2: 1e-06\n",
            "\tLinear Window: 0\n",
            "\tLinear Shared Weights: False\n",
            "\tRevIN: False\n",
            "\tDecomposition: False\n",
            "GlobalSelfAttn: AttentionLayer(\n",
            "  (inner_attention): FullAttention(\n",
            "    (dropout): Dropout(p=0.0, inplace=False)\n",
            "  )\n",
            "  (query_projection): Linear(in_features=200, out_features=800, bias=True)\n",
            "  (key_projection): Linear(in_features=200, out_features=800, bias=True)\n",
            "  (value_projection): Linear(in_features=200, out_features=800, bias=True)\n",
            "  (out_projection): Linear(in_features=800, out_features=200, bias=True)\n",
            "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
            ")\n",
            "GlobalCrossAttn: AttentionLayer(\n",
            "  (inner_attention): FullAttention(\n",
            "    (dropout): Dropout(p=0.0, inplace=False)\n",
            "  )\n",
            "  (query_projection): Linear(in_features=200, out_features=800, bias=True)\n",
            "  (key_projection): Linear(in_features=200, out_features=800, bias=True)\n",
            "  (value_projection): Linear(in_features=200, out_features=800, bias=True)\n",
            "  (out_projection): Linear(in_features=800, out_features=200, bias=True)\n",
            "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
            ")\n",
            "LocalSelfAttn: AttentionLayer(\n",
            "  (inner_attention): FullAttention(\n",
            "    (dropout): Dropout(p=0.0, inplace=False)\n",
            "  )\n",
            "  (query_projection): Linear(in_features=200, out_features=800, bias=True)\n",
            "  (key_projection): Linear(in_features=200, out_features=800, bias=True)\n",
            "  (value_projection): Linear(in_features=200, out_features=800, bias=True)\n",
            "  (out_projection): Linear(in_features=800, out_features=200, bias=True)\n",
            "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
            ")\n",
            "LocalCrossAttn: AttentionLayer(\n",
            "  (inner_attention): FullAttention(\n",
            "    (dropout): Dropout(p=0.0, inplace=False)\n",
            "  )\n",
            "  (query_projection): Linear(in_features=200, out_features=800, bias=True)\n",
            "  (key_projection): Linear(in_features=200, out_features=800, bias=True)\n",
            "  (value_projection): Linear(in_features=200, out_features=800, bias=True)\n",
            "  (out_projection): Linear(in_features=800, out_features=200, bias=True)\n",
            "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
            ")\n",
            "Using Embedding: spatio-temporal\n",
            "Time Emb Dim: 6\n",
            "Space Embedding: True\n",
            "Time Embedding: True\n",
            "Val Embedding: True\n",
            "Given Embedding: True\n",
            "Null Value: None\n",
            "Pad Value: None\n",
            "Reconstruction Dropout: Timesteps 0.05, Standard 0.1, Seq (max len = 5) 0.2, Skip All Drop 1.0\n",
            " *** Spacetimeformer (v1.5) Summary: *** \n",
            "\t\tModel Dim: 200\n",
            "\t\tFF Dim: 800\n",
            "\t\tEnc Layers: 3\n",
            "\t\tDec Layers: 3\n",
            "\t\tEmbed Dropout: 0.2\n",
            "\t\tFF Dropout: 0.3\n",
            "\t\tAttn Out Dropout: 0.0\n",
            "\t\tAttn Matrix Dropout: 0.0\n",
            "\t\tQKV Dropout: 0.0\n",
            "\t\tL2 Coeff: 1e-06\n",
            "\t\tWarmup Steps: 0\n",
            "\t\tNormalization Scheme: batch\n",
            "\t\tAttention Time Windows: 1\n",
            "\t\tShifted Time Windows: False\n",
            "\t\tPosition Emb Type: abs\n",
            "\t\tRecon Loss Imp: 0.0\n",
            " ***                                  *** \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:467: LightningDeprecationWarning: Setting `Trainer(gpus=[0])` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=[0])` instead.\n",
            "  rank_zero_deprecation(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
            "  rank_zero_warn(\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name            | Type            | Params\n",
            "----------------------------------------------------\n",
            "0 | spacetimeformer | Spacetimeformer | 13.5 M\n",
            "----------------------------------------------------\n",
            "13.5 M    Trainable params\n",
            "0         Non-trainable params\n",
            "13.5 M    Total params\n",
            "54.149    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd9025f66b184c21aee13069a5b63cf8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "accuracy() missing 1 required positional argument: 'task'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-cd42b5720191>\u001b[0m in \u001b[0;36m<cell line: 102>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecaster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;31m# Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"`Trainer.fit()` requires a `LightningModule`, got: {model.__class__.__qualname__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    609\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}: trainer tearing down\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0misolate_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;31m# enable train mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1265\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m                 \u001b[0mval_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_sanity_check_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_dataloaders\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataloader_idx\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mdl_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_max_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# store batch level output per dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36m_evaluation_step\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \"\"\"\n\u001b[1;32m    233\u001b[0m         \u001b[0mhook_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test_step\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{self.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m         \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValidationStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacetimeformer/forecaster.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_val_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacetimeformer/spacetimeformer_model/spacetimeformer_model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, batch, train)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# compute all loss values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         loss_dict = self.compute_loss(\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mtime_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacetimeformer/spacetimeformer_model/spacetimeformer_model.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, batch, time_mask, forward_kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spatio-temporal\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_loss_imp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;31m# space emb classification loss (detached)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mclass_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mclass_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacetimeformer/spacetimeformer_model/spacetimeformer_model.py\u001b[0m in \u001b[0;36mclassification_loss\u001b[0;34m(self, logits, labels)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mclass_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         acc = torchmetrics.functional.accuracy(\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: accuracy() missing 1 required positional argument: 'task'"
          ]
        }
      ],
      "source": [
        "log_dir = STF_LOG_DIR\n",
        "if log_dir is None:\n",
        "    log_dir = \"./data/STF_LOG_DIR\"\n",
        "    print(\n",
        "        \"Using default wandb log dir path of ./data/STF_LOG_DIR. This can be adjusted with the environment variable `STF_LOG_DIR`\"\n",
        "    )\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "\n",
        "if ARG_CONFIG.wandb:\n",
        "    import wandb\n",
        "\n",
        "    project = STF_WANDB_PROJ\n",
        "    entity = STF_WANDB_ACCT\n",
        "    assert (\n",
        "        project is not None and entity is not None\n",
        "    ), \"Please set environment variables `STF_WANDB_ACCT` and `STF_WANDB_PROJ` with \\n\\\n",
        "        your wandb user/organization name and project title, respectively.\"\n",
        "    experiment = wandb.init(\n",
        "        project=project,\n",
        "        entity=entity,\n",
        "        config=ARG_CONFIG,\n",
        "        dir=log_dir,\n",
        "        reinit=True,\n",
        "    )\n",
        "    config = wandb.config\n",
        "    wandb.run.name = ARG_CONFIG.run_name\n",
        "    wandb.run.save()\n",
        "    logger = pl.loggers.WandbLogger(\n",
        "        experiment=experiment,\n",
        "        save_dir=log_dir,\n",
        "    )\n",
        "\n",
        "# Dset\n",
        "(\n",
        "    data_module,\n",
        "    inv_scaler,\n",
        "    scaler,\n",
        "    null_val,\n",
        "    plot_var_idxs,\n",
        "    plot_var_names,\n",
        "    pad_val,\n",
        ") = create_dset(ARG_CONFIG)\n",
        "\n",
        "# Model\n",
        "ARG_CONFIG.null_value = null_val\n",
        "ARG_CONFIG.pad_value = pad_val\n",
        "forecaster = create_model(ARG_CONFIG)\n",
        "forecaster.set_inv_scaler(inv_scaler)\n",
        "forecaster.set_scaler(scaler)\n",
        "forecaster.set_null_value(null_val)\n",
        "\n",
        "# Callbacks\n",
        "callbacks = create_callbacks(ARG_CONFIG, save_dir=log_dir)\n",
        "test_samples = next(iter(data_module.test_dataloader()))\n",
        "\n",
        "if ARG_CONFIG.wandb and ARG_CONFIG.plot:\n",
        "    callbacks.append(\n",
        "        stf.plot.PredictionPlotterCallback(\n",
        "            test_samples,\n",
        "            var_idxs=plot_var_idxs,\n",
        "            var_names=plot_var_names,\n",
        "            pad_val=pad_val,\n",
        "            total_samples=min(ARG_CONFIG.plot_samples, ARG_CONFIG.batch_size),\n",
        "        )\n",
        "    )\n",
        "\n",
        "if ARG_CONFIG.wandb and ARG_CONFIG.model == \"spacetimeformer\" and ARG_CONFIG.attn_plot:\n",
        "\n",
        "    callbacks.append(\n",
        "        stf.plot.AttentionMatrixCallback(\n",
        "            test_samples,\n",
        "            layer=0,\n",
        "            total_samples=min(16, ARG_CONFIG.batch_size),\n",
        "        )\n",
        "    )\n",
        "\n",
        "if ARG_CONFIG.wandb:\n",
        "    config.update(ARG_CONFIG)\n",
        "    logger.log_hyperparams(config)\n",
        "\n",
        "if ARG_CONFIG.val_check_interval <= 1.0:\n",
        "    val_control = {\"val_check_interval\": ARG_CONFIG.val_check_interval}\n",
        "else:\n",
        "    val_control = {\"check_val_every_n_epoch\": int(ARG_CONFIG.val_check_interval)}\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    gpus=ARG_CONFIG.gpus,\n",
        "    callbacks=callbacks,\n",
        "    logger=logger if ARG_CONFIG.wandb else None,\n",
        "    accelerator=\"cuda\",\n",
        "    gradient_clip_val=ARG_CONFIG.grad_clip_norm,\n",
        "    gradient_clip_algorithm=\"norm\",\n",
        "    overfit_batches=20 if ARG_CONFIG.debug else 0,\n",
        "    accumulate_grad_batches=ARG_CONFIG.accumulate,\n",
        "    sync_batchnorm=True,\n",
        "    limit_val_batches=ARG_CONFIG.limit_val_batches,\n",
        "    **val_control,\n",
        ")\n",
        "\n",
        "# Train\n",
        "trainer.fit(forecaster, datamodule=data_module)\n",
        "\n",
        "# Test\n",
        "trainer.test(datamodule=data_module, ckpt_path=\"best\")\n",
        "\n",
        "# Predict (only here as a demo and test)\n",
        "# forecaster.to(\"cuda\")\n",
        "# xc, yc, xt, _ = test_samples\n",
        "# yt_pred = forecaster.predict(xc, yc, xt)\n",
        "\n",
        "if ARG_CONFIG.wandb:\n",
        "    experiment.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forecaster.to(\"cuda\")\n",
        "xc, yc, xt, _ = test_samples\n",
        "yt_pred = forecaster.predict(xc, yc, xt)"
      ],
      "metadata": {
        "id": "xUpMMKOzs5gG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bd9025f66b184c21aee13069a5b63cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b2b7854fb5d43df9c588babdd47765c",
              "IPY_MODEL_b3cd7f114a5d4d46bf08c0431a739a4b",
              "IPY_MODEL_fcbaa5644b934102a4cee15b07dc4455"
            ],
            "layout": "IPY_MODEL_3f52110e9f5d4eb08f4b59d98fd0d9ae"
          }
        },
        "6b2b7854fb5d43df9c588babdd47765c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec1adbfa9a8140129260514c8cbd8a28",
            "placeholder": "​",
            "style": "IPY_MODEL_1d5f79b350e64fd98d6770be4a588107",
            "value": "Sanity Checking DataLoader 0:   0%"
          }
        },
        "b3cd7f114a5d4d46bf08c0431a739a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7864a0b6ac9144038845de640fee4da2",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_baf018ef05054c72a3addbbce76b75f8",
            "value": 0
          }
        },
        "fcbaa5644b934102a4cee15b07dc4455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60437c4fd3184227bf9a8cc684d61fa7",
            "placeholder": "​",
            "style": "IPY_MODEL_e8d56a503f6040d88643bd95c8483380",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "3f52110e9f5d4eb08f4b59d98fd0d9ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "ec1adbfa9a8140129260514c8cbd8a28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d5f79b350e64fd98d6770be4a588107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7864a0b6ac9144038845de640fee4da2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baf018ef05054c72a3addbbce76b75f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60437c4fd3184227bf9a8cc684d61fa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8d56a503f6040d88643bd95c8483380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}